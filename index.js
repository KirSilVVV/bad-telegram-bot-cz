// index.js
// Telegram (Telegraf) â†’ OCR / file text extraction â†’ Voiceflow Runtime API
// âœ… Works on Node 18+ (you have Node 24)
// âœ… Robust PDF text extraction + OCR for scanned PDFs (no external poppler needed)
// âœ… Logs extracted text + DEBUG pipeline logs
// âœ… Voiceflow traces: text / speak / message
//
// Install deps:
// npm i telegraf axios dotenv sharp tesseract.js pdf-parse mammoth file-type
// npm i pdfjs-dist @napi-rs/canvas
//
// package.json must include:
// { "type": "module" }
//
// .env:
// TELEGRAM_BOT_TOKEN=...
// VOICEFLOW_API_KEY=...
// VOICEFLOW_VERSION_ID=...

import 'dotenv/config';
import axios from 'axios';
import { Telegraf } from 'telegraf';

import fs from 'fs/promises';
import path from 'path';
import sharp from 'sharp';
import Tesseract from 'tesseract.js';
import mammoth from 'mammoth';
import { fileTypeFromBuffer } from 'file-type';

import { createRequire } from 'module';
const require = createRequire(import.meta.url);

// pdf-parse is CommonJS function (confirmed in your env)
const pdfParse = require('pdf-parse');

// PDF rendering (pure JS) for OCR of scanned PDFs
import * as pdfjsLib from 'pdfjs-dist/legacy/build/pdf.mjs';
import { createCanvas } from '@napi-rs/canvas';

const TELEGRAM_BOT_TOKEN = process.env.TELEGRAM_BOT_TOKEN;
const VF_API_KEY = process.env.VOICEFLOW_API_KEY;
const VF_VERSION_ID = process.env.VOICEFLOW_VERSION_ID;

const DEBUG = true;
const dbg = (...args) => DEBUG && console.log('[DEBUG]', ...args);

if (!TELEGRAM_BOT_TOKEN || !VF_API_KEY || !VF_VERSION_ID) {
    console.error('âŒ Missing .env vars: TELEGRAM_BOT_TOKEN, VOICEFLOW_API_KEY, VOICEFLOW_VERSION_ID');
    process.exit(1);
}

const bot = new Telegraf(TELEGRAM_BOT_TOKEN);

const TMP_DIR = path.join(process.cwd(), 'tmp');
const LOG_DIR = path.join(process.cwd(), 'logs');

const MAX_IMG_MB = 15;
const MAX_DOC_MB = 20;
const VF_MAX_TEXT = 6000;

// If pdf-parse returns less text than this â†’ treat as scan and run OCR
const PDF_TEXT_MIN_LEN = 30;

// OCR limits (avoid huge CPU time)
const PDF_OCR_MAX_PAGES = 3; // increase if needed
const PDF_OCR_SCALE = 2.0;   // 2.0â€“2.5 usually good

async function ensureDir(dirPath) {
    try {
        await fs.mkdir(dirPath, { recursive: true });
    } catch { }
}

function truncate(text, maxLen = VF_MAX_TEXT) {
    if (!text) return '';
    return text.length > maxLen ? text.slice(0, maxLen) + '\nâ€¦[obezÌŒaÌno]' : text;
}

function safeShort(text, max = 350) {
    const s = (text || '').replace(/\s+/g, ' ').trim();
    return s.length > max ? s.slice(0, max) + 'â€¦' : s;
}

function sanitizeFilename(name) {
    return String(name || 'file')
        .replace(/[^\w.\-]+/g, '_')
        .slice(0, 120);
}

async function logExtracted({ userId, kind, fileName, extracted }) {
    await ensureDir(LOG_DIR);

    const ts = new Date().toISOString();
    const header = `[${ts}] user=${userId} kind=${kind} file=${fileName || '-'} chars=${(extracted || '').length}`;

    console.log(`ðŸ§¾ ${header} preview="${safeShort(extracted)}"`);

    const logPath = path.join(LOG_DIR, `responses_${ts.slice(0, 10)}.log`);
    const body =
        `${header}\n` +
        `--- BEGIN ---\n` +
        `${extracted || ''}\n` +
        `--- END ---\n\n`;

    await fs.appendFile(logPath, body, 'utf-8');
}

async function downloadTelegramFile(fileUrl, filename) {
    await ensureDir(TMP_DIR);
    const filePath = path.join(TMP_DIR, filename);

    dbg('Downloading:', { fileUrl, filename });

    const res = await axios.get(fileUrl, { responseType: 'arraybuffer', timeout: 60000 });
    await fs.writeFile(filePath, res.data);

    const stat = await fs.stat(filePath);
    dbg('Downloaded bytes:', { filePath, size: stat.size });

    return filePath;
}

async function extractTextFromImageBuffer(buf) {
    // preprocess for OCR
    const preprocessed = await sharp(buf)
        .resize({ width: 1600, withoutEnlargement: true })
        .toFormat('png')
        .toBuffer();

    const ocr = await Tesseract.recognize(preprocessed, 'rus+eng');
    return (ocr?.data?.text || '').trim();
}

function looksLikePdf(buf) {
    if (!buf || buf.length < 4) return false;
    return buf.slice(0, 4).toString('utf-8') === '%PDF';
}

async function ocrPdfBuffer(pdfBuf, { maxPages = PDF_OCR_MAX_PAGES, scale = PDF_OCR_SCALE } = {}) {
    dbg('PDF OCR: start', { bytes: pdfBuf.length, maxPages, scale });

    const loadingTask = pdfjsLib.getDocument({ data: pdfBuf });
    const pdf = await loadingTask.promise;

    const numPages = pdf.numPages;
    const pagesToDo = Math.min(numPages, maxPages);

    dbg('PDF OCR: pages', { numPages, pagesToDo });

    let out = '';

    for (let p = 1; p <= pagesToDo; p++) {
        const page = await pdf.getPage(p);
        const viewport = page.getViewport({ scale });

        const canvas = createCanvas(Math.ceil(viewport.width), Math.ceil(viewport.height));
        const ctx = canvas.getContext('2d');

        // render page to canvas
        await page.render({ canvasContext: ctx, viewport }).promise;

        // canvas -> PNG buffer -> OCR
        const pngBuf = canvas.toBuffer('image/png');

        dbg('PDF OCR: page rendered', { page: p, w: canvas.width, h: canvas.height, pngBytes: pngBuf.length });

        const text = await extractTextFromImageBuffer(pngBuf);
        dbg('PDF OCR: page text length', { page: p, len: text.length });

        if (text) {
            out += `\n\n[PAGE ${p}]\n${text}`;
        }
    }

    return out.trim();
}

async function extractTextFromFile(filePath, hintedNameOrMime = '') {
    const buf = await fs.readFile(filePath);

    dbg('First bytes (hex):', buf.slice(0, 8).toString('hex'));
    const ft = await fileTypeFromBuffer(buf);
    dbg('fileTypeFromBuffer:', ft);

    // 1) Image â†’ OCR
    if (ft && ['image/png', 'image/jpeg', 'image/webp'].includes(ft.mime)) {
        dbg('Extractor branch: image OCR');
        return await extractTextFromImageBuffer(buf);
    }

    // 2) PDF â†’ text, and if scan â†’ OCR
    const isPdf =
        (ft && ft.mime === 'application/pdf') ||
        looksLikePdf(buf) ||
        String(hintedNameOrMime).toLowerCase().includes('application/pdf') ||
        filePath.toLowerCase().endsWith('.pdf');

    if (isPdf) {
        dbg('Extractor branch: PDF');

        // First attempt: text layer
        const data = await pdfParse(buf);
        const txt = (data?.text || '').trim();
        dbg('pdf-parse text length:', txt.length);

        if (txt.length >= PDF_TEXT_MIN_LEN) return txt;

        // Fallback: OCR for scanned PDF
        dbg('PDF seems scanned or empty â†’ OCR fallback');
        const ocrText = await ocrPdfBuffer(buf, { maxPages: PDF_OCR_MAX_PAGES, scale: PDF_OCR_SCALE });
        dbg('PDF OCR total length:', ocrText.length);

        return ocrText; // may still be empty; caller will handle
    }

    // 3) DOCX â†’ text
    if (filePath.toLowerCase().endsWith('.docx')) {
        dbg('Extractor branch: DOCX');
        const result = await mammoth.extractRawText({ path: filePath });
        return (result?.value || '').trim();
    }

    // 4) Plain text fallback
    dbg('Extractor branch: plain text fallback');
    try {
        return buf.toString('utf-8').trim();
    } catch {
        return '';
    }
}

function collectVoiceflowMessages(traces) {
    const messages = [];
    if (!Array.isArray(traces)) return messages;

    for (const t of traces) {
        if (t?.type === 'text' && t?.payload?.message) messages.push(t.payload.message);
        else if (t?.type === 'speak' && t?.payload?.message) messages.push(t.payload.message);
        else if (t?.type === 'message' && t?.payload?.message) messages.push(t.payload.message);
    }
    return messages;
}

async function voiceflowInteract(userId, text) {
    const url = `https://general-runtime.voiceflow.com/state/${VF_VERSION_ID}/user/${userId}/interact`;

    dbg('Sending to Voiceflow chars:', text?.length || 0);
    dbg('Sending preview:', safeShort(text, 500));

    const res = await axios.post(
        url,
        { request: { type: 'text', payload: text } },
        {
            headers: {
                Authorization: VF_API_KEY,
                'Content-Type': 'application/json',
            },
            timeout: 200000,
        }
    );

    const traces = res.data;

    if (Array.isArray(traces)) dbg('Voiceflow traces types:', traces.map((t) => t?.type));
    else dbg('Voiceflow raw response (non-array):', traces);

    const messages = collectVoiceflowMessages(traces);

    if (!messages.length && DEBUG) dbg('Voiceflow raw traces:', JSON.stringify(traces, null, 2));

    return messages.length
        ? messages.join('\n')
        : 'Ð¯ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð» Ð´Ð°Ð½Ð½Ñ‹Ðµ, Ð½Ð¾ Ð˜Ð˜ Ð½Ðµ Ð²ÐµÑ€Ð½ÑƒÐ» Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ, ÐµÑÑ‚ÑŒ Ð»Ð¸ Ð² ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ð¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹.';
}

async function sendToVoiceflowAsUserTurn(userId, extractedText) {
    return await voiceflowInteract(userId, extractedText);
}

/* -------------------- Telegram handlers -------------------- */

bot.start(async (ctx) => {
    await ctx.reply(
        'Ð¯ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº, Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¹ Ð²Ð°ÑˆÐµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ. Ð’Ñ‹ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ Ð¸Ð»Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ PDF/DOCX Ð»Ð¸Ð±Ð¾ ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚.'
    );
});

// Text messages: log + send to Voiceflow
bot.on('text', async (ctx) => {
    const userId = String(ctx.from.id);
    const text = ctx.message.text;

    try {
        await logExtracted({ userId, kind: 'text', fileName: '-', extracted: text });
        await ctx.sendChatAction('typing');
        const reply = await voiceflowInteract(userId, text);
        await ctx.reply(reply);
    } catch (err) {
        console.error(err?.response?.data || err.message);
        await ctx.reply('Connection error. Check API key / Version ID.');
    }
});

// Photos / screenshots: OCR + log + send extracted text to Voiceflow
bot.on('photo', async (ctx) => {
    const userId = String(ctx.from.id);
    const photos = ctx.message.photo;
    const best = photos[photos.length - 1];

    if (best.file_size && best.file_size > MAX_IMG_MB * 1024 * 1024) {
        return ctx.reply(`Ð¤Ð°Ð¹Ð» ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð² ${MAX_IMG_MB} MB.`);
    }

    await ctx.reply('Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾. Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÑŽ Ñ‚ÐµÐºÑÑ‚â€¦');

    try {
        const link = await ctx.telegram.getFileLink(best.file_id);
        dbg('PHOTO file link:', link.href);

        const fileName = `photo_${best.file_id}.jpg`;
        const filePath = await downloadTelegramFile(link.href, fileName);

        const extracted = await extractTextFromFile(filePath, 'image');

        await logExtracted({ userId, kind: 'photo', fileName, extracted });

        if (!extracted || !extracted.trim()) {
            return ctx.reply(
                'ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ ðŸ˜•\n' +
                'ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ð±Ð¾Ð»ÐµÐµ Ñ‡Ñ‘Ñ‚ÐºÐ¸Ð¹ ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ PDF/DOCX, Ð»Ð¸Ð±Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚ÑŒÑ‚Ðµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼'
            );
        }

        await ctx.sendChatAction('typing');
        const reply = await sendToVoiceflowAsUserTurn(userId, truncate(extracted));
        await ctx.reply(reply);
    } catch (err) {
        console.error(err?.response?.data || err.message);
        await ctx.reply(
            'ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð±Ð¾Ð»ÐµÐµ Ñ‡Ñ‘Ñ‚ÐºÐ¸Ð¹ ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ PDF/DOCX.'
        );
    }
});

// Documents: extract + log + send extracted text to Voiceflow (PDF includes OCR fallback)
bot.on('document', async (ctx) => {
    const userId = String(ctx.from.id);
    const doc = ctx.message.document;

    dbg('DOC meta:', {
        file_id: doc.file_id,
        file_name: doc.file_name,
        mime_type: doc.mime_type,
        file_size: doc.file_size,
    });

    if (doc.file_size && doc.file_size > MAX_DOC_MB * 1024 * 1024) {
        return ctx.reply(`Ð¤Ð°Ð¹Ð» ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ Ð² ${MAX_DOC_MB} MB.`);
    }

    await ctx.reply('Ð¤Ð°Ð¹Ð» Ð±Ñ‹Ð» Ð¿Ñ€Ð¸Ð½ÑÑ‚. ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÑŽ Ñ‚ÐµÐºÑÑ‚â€¦');

    try {
        const link = await ctx.telegram.getFileLink(doc.file_id);
        dbg('DOC file link:', link.href);

        const safeName = sanitizeFilename(doc.file_name || `doc_${doc.file_id}`);
        const savedName = `${doc.file_id}_${safeName}`;
        const filePath = await downloadTelegramFile(link.href, savedName);

        const extracted = await extractTextFromFile(filePath, doc.mime_type || doc.file_name || '');

        await logExtracted({ userId, kind: 'document', fileName: doc.file_name || savedName, extracted });

        if (!extracted || !extracted.trim()) {
            return ctx.reply(
                'ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð° ðŸ˜•\n' +
                'Ð›ÑƒÑ‡ÑˆÐµ Ð²ÑÐµÐ³Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‚ PDF (Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ) Ð¸Ð»Ð¸ DOCX. Ð•ÑÐ»Ð¸ ÑÑ‚Ð¾ ÑÐºÐ°Ð½, Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ñ„Ð¾Ñ‚Ð¾ Ð¸Ð»Ð¸ ÑÐ½Ð¸Ð¼ÐºÐ¸ ÑÐºÑ€Ð°Ð½Ð° ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†.'
            );
        }

        await ctx.sendChatAction('typing');
        const reply = await sendToVoiceflowAsUserTurn(userId, truncate(extracted));
        await ctx.reply(reply);
    } catch (err) {
        console.error(err?.response?.data || err.message);
        await ctx.reply(
            'Ð¤Ð°Ð¹Ð» Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ. Ð›ÑƒÑ‡ÑˆÐµ Ð²ÑÐµÐ³Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‚ PDF (Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ) Ð¸Ð»Ð¸ DOCX. Ð”Ð»Ñ ÑÐºÐ°Ð½Ð¾Ð² Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ñ„Ð¾Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ð¸ Ð¸Ð»Ð¸ ÑÐ½Ð¸Ð¼ÐºÐ¸ ÑÐºÑ€Ð°Ð½Ð°.'
        );
    }
});

/* -------------------- start -------------------- */

const PORT = process.env.PORT || 3000;
const WEBHOOK_URL = process.env.RENDER_EXTERNAL_URL || 'https://bad-telegram-bot-cz.onrender.com';

// Use webhook mode for production (Render)
if (process.env.NODE_ENV === 'production') {
    console.log(`ðŸ¤– Bot is running in WEBHOOK mode on port ${PORT}...`);
    console.log(`ðŸ“Š Webhook URL: ${WEBHOOK_URL}`);
    console.log('ðŸ“Š PDF text + PDF OCR + OCR images + logging');

    // Use http module for explicit webhook handling
    import('http').then(({ createServer }) => {
        const server = createServer(async (req, res) => {
            // Only handle POST requests
            if (req.method === 'POST') {
                let body = '';
                req.on('data', chunk => body += chunk);
                req.on('end', async () => {
                    try {
                        const update = JSON.parse(body);
                        await bot.handleUpdate(update);
                        res.writeHead(200, { 'Content-Type': 'application/json' });
                        res.end(JSON.stringify({ ok: true }));
                    } catch (err) {
                        console.error('Webhook error:', err.message);
                        res.writeHead(500, { 'Content-Type': 'application/json' });
                        res.end(JSON.stringify({ ok: false, error: err.message }));
                    }
                });
            } else {
                // Return 403 for non-POST (expected behavior)
                res.writeHead(403, { 'Content-Type': 'text/plain' });
                res.end('Forbidden');
            }
        });

        server.listen(PORT, '0.0.0.0', () => {
            console.log(`âœ… HTTP webhook server listening on port ${PORT}`);

            // Set webhook with Telegram
            bot.telegram.setWebhook(`${WEBHOOK_URL}`).then(() => {
                console.log(`âœ… Telegram webhook set to: ${WEBHOOK_URL}`);
            }).catch(err => {
                console.error('âŒ Failed to set webhook:', err.message);
            });
        });

        // Graceful shutdown
        process.once('SIGINT', () => {
            console.log('Shutting down...');
            bot.stop('SIGINT');
            server.close();
        });
        process.once('SIGTERM', () => {
            console.log('Shutting down...');
            bot.stop('SIGTERM');
            server.close();
        });
    });
} else {
    // Development: polling mode
    console.log('ðŸ¤– Bot is running in POLLING mode (PDF text + PDF OCR + OCR images + logging + DEBUG)...');

    bot.launch();

    process.once('SIGINT', () => bot.stop('SIGINT'));
    process.once('SIGTERM', () => bot.stop('SIGTERM'));
}

